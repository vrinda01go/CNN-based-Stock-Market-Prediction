{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-19T18:23:05.594449Z","iopub.execute_input":"2022-06-19T18:23:05.594858Z","iopub.status.idle":"2022-06-19T18:23:05.607134Z","shell.execute_reply.started":"2022-06-19T18:23:05.594822Z","shell.execute_reply":"2022-06-19T18:23:05.606375Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv3D, MaxPool3D, Flatten, Dense\nfrom keras.layers import Dropout, Input, BatchNormalization\nfrom keras.utils import np_utils\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom plotly.offline import iplot, init_notebook_mode\nfrom keras.losses import categorical_crossentropy\nfrom tensorflow.keras.optimizers import Adam\nimport plotly.graph_objs as go\nfrom matplotlib.pyplot import cm\nfrom keras.models import Model\nimport numpy as np\nimport keras\nimport h5py","metadata":{"execution":{"iopub.status.busy":"2022-06-19T18:25:29.869137Z","iopub.execute_input":"2022-06-19T18:25:29.870369Z","iopub.status.idle":"2022-06-19T18:25:29.878636Z","shell.execute_reply.started":"2022-06-19T18:25:29.870258Z","shell.execute_reply":"2022-06-19T18:25:29.877601Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"with h5py.File(\"../input/3d-mnist/full_dataset_vectors.h5\", \"r\") as hf:    \n     X_train = hf[\"X_train\"][:]\n     y_train = hf[\"y_train\"][:]    \n     X_test = hf[\"X_test\"][:]  \n     y_test = hf[\"y_test\"][:] ","metadata":{"execution":{"iopub.status.busy":"2022-06-19T18:23:05.759308Z","iopub.execute_input":"2022-06-19T18:23:05.760118Z","iopub.status.idle":"2022-06-19T18:23:07.267345Z","shell.execute_reply.started":"2022-06-19T18:23:05.760081Z","shell.execute_reply":"2022-06-19T18:23:07.266373Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(\"X_train shape :\", (X_train.shape))\nprint(\"X_test shape :\" ,(X_test.shape))\nprint(\"Y_train shape :\" ,(y_train.shape))\nprint(\"Y_test shape :\" ,(y_test.shape))\n","metadata":{"execution":{"iopub.status.busy":"2022-06-19T18:23:07.269018Z","iopub.execute_input":"2022-06-19T18:23:07.269418Z","iopub.status.idle":"2022-06-19T18:23:07.275533Z","shell.execute_reply.started":"2022-06-19T18:23:07.269382Z","shell.execute_reply":"2022-06-19T18:23:07.274449Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"xtrain=np.ndarray((X_train.shape[0],4096,3))\nxtest=np.ndarray((X_test.shape[0],4096,3))\n\n# not exactly clear what this block is doing\ndef add_rgb_dimension(array):\n    scaler_map = cm.ScalarMappable(cmap=\"Oranges\")\n    array = scaler_map.to_rgba(array)[:, : -1]\n    return array\nfor i in range(X_train.shape[0]):\n    xtrain[i] = add_rgb_dimension(X_train[i])\nfor i in range(X_test.shape[0]):\n    xtest[i] = add_rgb_dimension(X_test[i])\n\n## convert to 1 + 4D space (1st argument represents number of rows in the dataset)\nxtrain = xtrain.reshape(X_train.shape[0], 16, 16, 16, 3)\nxtest = xtest.reshape(X_test.shape[0], 16, 16, 16, 3)\n\n## convert target variable into one-hot\ny_train = keras.utils.np_utils.to_categorical(y_train, 10)\ny_test = keras.utils.np_utils.to_categorical(y_test, 10)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-19T18:23:07.276756Z","iopub.execute_input":"2022-06-19T18:23:07.277110Z","iopub.status.idle":"2022-06-19T18:23:14.514670Z","shell.execute_reply.started":"2022-06-19T18:23:07.277069Z","shell.execute_reply":"2022-06-19T18:23:14.513321Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(xtrain.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T18:23:14.517242Z","iopub.execute_input":"2022-06-19T18:23:14.517855Z","iopub.status.idle":"2022-06-19T18:23:14.524182Z","shell.execute_reply.started":"2022-06-19T18:23:14.517808Z","shell.execute_reply":"2022-06-19T18:23:14.523059Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# One Input layer with dimentions 16, 16, 16, 3\n# Output layer with dimentions 10\n# Apply 4 Convolutional layer with increasing order of filter size (standard size : 8, 16, 32, 64) and fixed kernel size = (3, 3, 3)\n# Apply 2 Max Pooling layers, one after 2nd convolutional layer and one after fourth convolutional layer.\n# Batch normalization on convolutiona architecture\n# Dense layers with 2 layers followed by dropout to avoid overfitting","metadata":{"execution":{"iopub.status.busy":"2022-06-19T18:23:14.525806Z","iopub.execute_input":"2022-06-19T18:23:14.526273Z","iopub.status.idle":"2022-06-19T18:23:14.540815Z","shell.execute_reply.started":"2022-06-19T18:23:14.526241Z","shell.execute_reply":"2022-06-19T18:23:14.539582Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"sample_shape=(16,16,16,3)\nmodel=Sequential()\nmodel.add(Conv3D(filters=8,kernel_size=(3,3,3),activation='relu',input_shape=sample_shape))\nmodel.add(Conv3D(filters=16,kernel_size=(3,3,3),activation='relu'))\nmodel.add(MaxPool3D(pool_size=(2,2,2)))\nmodel.add(Conv3D(filters=32,kernel_size=(3,3,3),activation='relu'))\nmodel.add(Conv3D(filters=64,kernel_size=(3,3,3),activation='relu'))\nmodel.add(MaxPool3D(pool_size=(2,2,2)))\nmodel.add(BatchNormalization())\n#dense layer requires input in single-dimensional shape i.e. 1-D array.\nmodel.add(Flatten())\nmodel.add(Dense(2048,activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10,activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(lr=0.001),\n              metrics=['accuracy'])\nmodel.summary()\nmodel.fit(x=xtrain, y=y_train, batch_size=128, epochs=50, validation_split=0.2)\n\n\n          ","metadata":{"execution":{"iopub.status.busy":"2022-06-19T18:26:36.144985Z","iopub.execute_input":"2022-06-19T18:26:36.145431Z","iopub.status.idle":"2022-06-19T18:33:10.531121Z","shell.execute_reply.started":"2022-06-19T18:26:36.145396Z","shell.execute_reply":"2022-06-19T18:33:10.529170Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model.predict(xtest)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T18:35:47.490715Z","iopub.execute_input":"2022-06-19T18:35:47.491129Z","iopub.status.idle":"2022-06-19T18:35:48.539969Z","shell.execute_reply.started":"2022-06-19T18:35:47.491097Z","shell.execute_reply":"2022-06-19T18:35:48.539044Z"},"trusted":true},"execution_count":34,"outputs":[]}]}